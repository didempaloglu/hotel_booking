---
title: "Machine Learning Project "
author: "Didem Paloglu"
date: "`r Sys.Date()`"
output: html_document

---

```{r setup, include=FALSE}
library(knitr)
library(vcd)
opts_chunk$set(out.extra='style="display:block; margin: auto"',
fig.align="center", fig.width=4, fig.height=4)
opts_knit$set(progress = FALSE, verbose = TRUE)
```

```{r, echo=FALSE, include=FALSE}

# installing required packages

library(dplyr)
library(magrittr)
library(ggplot2)
library(gridExtra)
library(corrplot)
library(caret)
library(readr)
library(tibble)
library(purrr)
library(DescTools)
library(lmtest)
library(Information)
library(janitor)
library(olsrr)
library(verification)
library(class)
library(kernlab)
library(kableExtra)
library(sjPlot)
library(bestNormalize)
library(lattice)
library(glmnet)

```

## Average Daily Rate of Hotel Bookings' Prediction with Linear Regression

### 1. INTRODUCTION

Hotel bookings are very common in every day life. When we consider the factors that lead us to pay more for an hotel, we can analyze factors affecting the daily income of hotels.  

The dataset contains different booking informations about two different hotel: City Hotel and Resort Hotel. Each observation represents a hotel booking. The dataset contains bookings due to arrive between the 1st of July of 2015 and the 31st of August 2017, including bookings that effectively arrived and bookings that were canceled. This is a real data set and it is avaliable at [Kaggle - Hotel Booking Demand Dataset](https://www.kaggle.com/jessemostipak/hotel-booking-demand).

In this project, the goal is the development of prediction models with regression of hotel booking's average daily rate. It measures the average rental revenue earned for an occupied room per day. First, train and test samples was created and then train dataset was prepared for the linear regression. Prediction quality of the train data was compared on the test data. In final,the model accuracy tested with different methods.

#### 1.1. Exploring the Data

```{r include=FALSE}

booking <- read.csv("hotel_bookings.csv", sep=";")

booking <- booking[!(booking$adr== 0), ] # removing the rows with 0 ADR

```

The dataset consists 119390 rows and 29 columns. There are both numerical and categorical variables in the dataset. The dependent variable is "adr" which is numerical. In the analysis,few rows having "0" ADR value were not included since it is not meaningful to analyze a zero rate. After removing observations that have 0 ADR value, total observations are 117431. All variables are listed as below: 

| Variable Name | Variable Type | Description |
|:------|:-----|:-----|
| adr    | Numeric   | Average Daily Rate |
| adults    | Integer  | Number of adults |
| arrival_date_day_of_month     |   Integer  | Day of the month of the arrival date |
| arrival_date_month    |  Categorical   | Month of arrival date with 12 categories: “January” to “December” |
| arrival_date_week_number    |  Integer   | Week number of the arrival date |
| arrival_date_year    | Integer  | Year of arrival date |
| assigned_room_type    | Categorical   | Code for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g.overbooking) or by customer request.Code is presented instead of designation for anonymity reasons |
| babies    | Integer   | Number of babies |
| booking_changes    |  Integer  | Number of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation |
| children    |  Integer  | Number of children |
| customer_type    |  Categorical  | Type of booking, assuming one of four categories:<br>Contract - when the booking has an allotment or other type of contract associated to it;<br>Group–when the booking is associated to a group;<br>Transient–when the booking is notpart of a group or contract, and is not associated to other transient booking;<br>Transient-party–when the booking istransient, but is associated to at least other transient booking |
| days_in_waiting_list    |  Integer  | Number of days the booking was in the waiting list before it was confirmed to the customer |
| deposit_type    | Categorical   |  Indication on if the customer made a deposit to guarantee the booking. This variable can assume three categories:<br>No Deposit–no deposit was made; <br>Non Refund–a deposit was made in the value of the total stay cost;<br>Refundable–a deposit was made witha value under the total cost of stay |
| distribution_channel    | Categorical   | Booking distribution channel. The term “TA” means “Travel Agents” and “TO” means “Tour Operators" |
| is_canceled    |  Categorical  | Value indicating if the booking was canceled (1) or not (0) |
| is_repeated_guest     |  Categorical  | Value indicating if the booking name was from a repeated guest (1) or not (0) |
| lead_time    | Integer   | Number of days that elapsed between the entering date of the booking into the PMS and the arrival date |
| market_segment    |  Categorical  | Market segment designation. Incategories, the term “TA” means “TravelAgents” and “TO” means “TourOperators” |
| meal    | Categorical   | Type of meal booked. Categories are presented in standard hospitality mealpackages:<br>Undefined/SC–no meal package;<br>BB–Bed & Breakfast;<br>HB–Half board (breakfast and one other meal–usually dinner);<br>FB–Full board (breakfast, lunch anddinner |
| previous_bookings_not_canceled    |  Integer  | Number of previous bookings not cancelled by the customer prior to the current booking |
| previous_cancellations    | Integer   | Number of previous bookings that were cancelled by the customer prior to the current booking |
| required_car_parking_spaces    |  Integer  | Number of car parking spaces required by the customer |
| reservation_status    |  Categorical  |   Reservation last status, assuming one of three categories:<br>Canceled–booking was canceled bythe customer;<br>Check-Out–customer has checked inbut already departed;<br>No-Show–customer did not check-in and did inform the hotel of the reason why |
| reservation_status_date    |  Date  | Date at which the last status was set. This variable can be used in conjunction with the ReservationStatus to understand when was the booking canceled or when did the customer checked-out of the hotel |
| reserved_room_type    |  Categorical  | Code of room type reserved. Code is presented instead of designation for anonymity reasons |
| stays_in_weekend_nights    |  Integer  | Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel |
| stays_in_week_nights    | Integer   | Number of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel |
| total_of_special_requests    |  Integer | Number of special requests made by the customer (e.g. twin bed or highfloor) |

***

We can see the head of dataset as below: 

```{r, echo=FALSE}

booking[1:10,] %>%
  kable(align = "lccrr", caption = "Dataset Table with First  10 row") %>% scroll_box(width = "100%")

```

***

#### 1.2. Insights About Data

Before starting the machine learning algorithms, let's look at the data deeply and get some insights about variables. As can seen below, some variables such as is_canceled and is_repeated_guest should be converted to factor. After converting variables, the structure of the dataset looks like as below:

```{r include=FALSE}

# integers into factor
booking$is_canceled <- as.factor(booking$is_canceled)
booking$is_repeated_guest <- as.factor(booking$is_repeated_guest)
booking$reservation_status_date <- as.Date.character(booking$reservation_status_date, tryFormats = c("%Y.%m.%d"))

```

```{r, echo=FALSE}

glimpse(booking)
summary(booking)

```

With `summary()` function, it can be said that:

* Average ADR of the bookings is $103.49
* 66,5% of the customers booked city hotel.
* Cancelization rate of the bookings is low since mean of the cancelazitation is close to zero.
* Most people choose to go to hotels at August. 
* Average stays is 2.5 nights in weekdays and almost 1 nights for the weekend.
* Distribution channels of bookings is mostly (nearly 82.5%) through Travel Agency/Tour Operator.
* 77,3% of the bookings consists bed & breakfast.
* 87,4% of customers preferred a non-deposit booking.

<br>
After examining the structure and summary findings about the data, we need to check if dataset consists any missing value. There is no missing values in the dataset. 


```{r, echo=FALSE}

colSums(is.na(booking)) %>% 
  sort()

```



Let's see some descriptive plots to understand dataset.

The left figure below shows the distribution of ADRs of bookings. According to the figure, average ADR of bookings is around $100 and there are some outliers which are greater than 500. The middle figure shows that the distribution of ADR is right skewed. Later, we will apply some transformation methods to obtain more normal distribution. Right figure shows that the room type H has the highest ADR, while the room type "L" has the lowest ADR.

```{r echo=FALSE, fig.height=4, fig.width= 8}
### Descriptive Visualization

# Distribution of ADR

p1 <- ggplot(booking, aes(adr)) +
  geom_boxplot() +
  ggtitle("Avearage Daily Rates of Bookings") +
  theme(plot.title = element_text(size = 10, face = "bold"))

p2 <- ggplot(booking,
       aes(x = adr)) +
  geom_histogram(fill = "blue",
                 bins = 100) +
  theme_bw() +
  ggtitle("Distribution of ADR") +
  theme(plot.title = element_text(size = 10, face = "bold"))

# mean adr by room type       
p3 <- ggplot(data = booking,
       aes(x=assigned_room_type, y=adr)) +
  stat_summary(fun="mean", geom="bar", fill="darkgreen")+
  ggtitle("Average ADR by Room Type") +
  theme(plot.title = element_text(size = 10, face = "bold"))

grid.arrange(p1, p2,p3, ncol=3)

```

<br>

The left figure below shows the cancelazation frequencies by hotel type. It can be said that cancelazation of bookings is higher in city hotels than resort hotels. Moreover, total bookings are also higher than resort hotels. The right figure below shos the arrival time of guests to the hotels. It can be understood that most bookings were made in summer and people prefer to go to hotels mostly in August. 

```{r echo=FALSE, fig.height=4, fig.width= 7}
# Cancelization by Hotel Type
p4 <- ggplot(data = booking,aes(x = is_canceled, fill=is_canceled)) + 
  geom_bar() +
  xlab("Canceled Bookings") +
  ylab("Frequencies") +
  ggtitle("Cancelazation Frequencies by Hotel") +
  theme(plot.title = element_text(size = 10, face = "bold")) +
  facet_grid(~hotel)

# Most frequent arrival months

p5 <- booking %>%
  group_by(arrival_date_month) %>%
  summarise(Count = n()) %>%
  arrange(-Count) %>%
  ggplot(aes(x = reorder(arrival_date_month, Count), Count)) +
  ylab("Frequencies") +
  geom_bar(stat = 'identity',fill = "purple") + 
  coord_flip() + 
  geom_text(aes(x =arrival_date_month, y=0.02, label= Count),
                 hjust=-1, vjust=0, size=4, 
                 colour="white",
                 angle=360) +
ggtitle("Arrival Month Frequencies") +
  theme(plot.title = element_text(size = 10, face = "bold"))

grid.arrange(p4, p5, ncol=2)

```

<br>

Another factor investigated is weekdays/weekend stay preferences. Most people book a room at most two weekends. In weekdays, people stay in hotels mostly for 0-10 days. 

```{r echo=FALSE, fig.height=4, fig.width= 8}

# Stays Length by Hotel

p6 <- ggplot(booking, aes(stays_in_week_nights, fill = hotel)) +
  geom_bar(aes(y=(..count..)), position="dodge") +
  ylab("Frequency") +
  ggtitle("Number of Stays in Weekdays by Hotel") +
  theme(plot.title = element_text(size = 10, face = "bold"))

p7 <- ggplot(booking, aes(stays_in_weekend_nights, fill = hotel)) +
  geom_bar(aes(y=(..count..)), position="dodge") +
  ylab("Frequency") +
  ggtitle("Number of Stays in Weekend by Hotel") +
  theme(plot.title = element_text(size = 10, face = "bold"))

grid.arrange(p6, p7, ncol=2)
```

<br> 

Last descriptive graph in below shows the rate of distribution channel of bookings. It can be said that 82.5% of bookings made by either travel agencies or tour operators followed by direct bookings with 11.8%. 

```{r echo=FALSE, fig.height=5, fig.width= 5}

#Distribution Channel

data <- data.frame(Categories= booking$distribution_channel, b=1:length(booking$distribution_channel))

data <- data %>% 
  group_by(Categories) %>% 
  count() %>% 
  ungroup() %>% 
  mutate(per=`n`/sum(`n`)) %>% 
  arrange(desc(Categories))

data$label <- scales::percent(data$per)

ggplot(data=data)+
  geom_bar(aes(x="", y=per, fill=Categories), stat="identity", width = 1)+
  coord_polar("y", start=0)+
  theme_void()+
  geom_text(aes(x=1, y = cumsum(per) - per/2, label=label)) +
  theme(plot.title = element_text(size = 10, face = "bold")) +
  ggtitle("Distribution Channels of Bookings")


```

***

##### 1.3.1. Data Pre-Processing

After initial descriptive analysis, in order to start machine learning analysis, we need to split data into train and test datasets. For a random division `set.seed()` should be run before  `createDataPartition()`. The data division was made as 70% for train sample and 30% for test sample. All variable selections and transformations will be based on the train dataset.

```{r, echo=FALSE}

# Dividing the data into training and testing sample

set.seed(987654321)

booking_which_training <- createDataPartition(booking$adr,
                                            p = 0.7, 
                                            list = FALSE) 
booking_train <- booking[booking_which_training,]
booking_test <- booking[-booking_which_training,]

```

Below, dimensions of the train and test samples are provided. Train data contains 82203 observations and test data contains 35228 observations.

```{r}

dim(booking_train)
dim(booking_test)

```

We can pre-select variables for the model to check the relation of each of them separately with the outcome variable. We can show relation of variables with target variable for both numerical variables and categorical variables. Correlation analysis is helpful to see the relationship of numerical independent variables with target variable and also helpful to detect if there is any collinearity among variables. ANOVA analysis is helpful to see the relation of the target variable with the categorical variables that most strongly associated with it.

Below is the correlation plot of numerical variables. The strongest relation is between arrival_date_week_number and arrival_date_year. But, this correlation does not imply a collinearity.  

```{r, echo=FALSE, warning=FALSE}

# Numeric columns
num_vars <-sapply(booking, is.numeric) %>% 
  which() %>% 
  names() 

booking_correlations <-
  cor(booking_train[,num_vars],
      use = "pairwise.complete.obs")

booking_numeric_vars_order <- 
  # we take correlations with the Sale_Price
  booking_correlations[,"adr"] %>% 
  # sort them in the decreasing order
  sort(decreasing = TRUE) %>%
  # end extract just variables' names
  names()

corrplot.mixed(booking_correlations[booking_numeric_vars_order, 
                                   booking_numeric_vars_order],
               upper = "circle",
               lower = "circle",
               tl.col="black", 
               tl.pos = "lt",
               tl.cex=0.6) 

```

After we looked at the relations between numerical independent variables and outcome variable, we looked also the relations between categorical independent variables and outcome variable. Below gives F-statistics of the ANOVA test. _reserved_room_type variable_ is highest associated with outcome and _reservation_status_ variable is least associated variable with the target variable.  

```{r echo=FALSE}
categ_vars <- 
  # check if variable is a factor
  sapply(booking, is.factor) %>% 
  # select those which are
  which() %>% 
  # and keep just their names
  names()

booking_F_anova <- function(categorical_vars) {
  anova_ <- aov(booking_train$adr ~ 
                  booking_train[[categorical_vars]]) 
  
  return(summary(anova_)[[1]][1, 4])
}

sapply(categ_vars,
       booking_F_anova) %>% 
  # in addition lets sort them
  # in the decreasing order of F
  #  and store as an object
  sort(decreasing = TRUE) -> booking_anova_all_categorical

booking_anova_all_categorical
```

Other issue is to check if a variable is linear combination of some other variables. When we test the linear combination of the variables, we can say that there is no linear combination in the dataset. 

```{r, echo=FALSE}

# linear combinations

( findLinearCombos(booking_train[, num_vars] ) ->
    booking_linearCombos ) 

```

Last thing to check about variables is near zero variance. If dataset has any variable with zero variance (it means that observations do not vary in variable), then it should be removed from the analysis. The result gives **TRUE** for days_in_waiting_list, babies, previous_bookings_not_canceled, is_repeated_guest and children. This implies that these variables will not be included in the linear regression.  

```{r, echo = FALSE}

booking_nzv_stats <- nearZeroVar(booking_train,
            saveMetrics = TRUE)


booking_nzv_stats %>%
  # we add rownames of the frame
  # (with names of variables)
  # as a new column in the data
  rownames_to_column("zmienna") %>%
  # and sort it in the descreasing order
  arrange(-zeroVar, -nzv, -freqRatio)

```

After removing zero variance variables, we have below variables to use as regressors in the train dataset for the linear regression:

```{r, echo=FALSE}

booking_variables_all <- names(booking_train)

booking_variables_nzv <- nearZeroVar(booking_train, 
                                      names = TRUE) 

booking_variables_selected <-
  booking_variables_all[!booking_variables_all %in% 
                         booking_variables_nzv]

print(booking_variables_selected)

```

All variables are prepared for machine learning processes and the following section gives how linear regression is applied for prediction of average daily rate of hotel bookings. 

### 2. METHODOLOGY

For obtaining a good model with high prediction accuracy, first step is constructing a reference model. This model will be compared with different models during the analysis and best model will be determined. Reference model constructed with two set of variables. In the first reference model, all variables selected in the previous section were used. The result gived a coefficient with NAs which is "reservation_status". So, second model did not include this variable. 

```{r include=FALSE}

# Reference models

options(contrasts = c("contr.treatment",  # for non-ordinal factors
                      "contr.treatment")) # for ordinal factors
```

```{r echo=TRUE}

# model with all variables

booking_lm1 <- lm(adr ~ .,
                 data = booking_train)


```

```{r echo=FALSE}
summary(booking_lm1)
```

```{r include=FALSE}

booking_variables_selected <-
  booking_variables_selected[-which(booking_variables_selected %in% 
                                c("reservation_status"))]
```

```{r echo=TRUE}
# model with selected variables

booking_lm2 <- lm(adr ~ ., 
                  data = booking_train %>% 
                    dplyr::select(all_of(booking_variables_selected)))

```

```{r echo=FALSE}

summary(booking_lm2)

```

According to results of reference models in above, first model is more powerful since it has higher R2 (0.6245). Second model (without NAs) was taken as reference model. Now, feature selection and feature transformation techniques will be applied on the train data. 

#### 2.1. Feature Selection

In this section, backward elimination were applied to reference model (booking_lm2) to remove uncessary variables from the analysis.  AIC and p-value techniques were used in backward elimination and compared with each other and results showed that "reservation_status_date" and "arrival_date_week_number" variables should be eliminated from the model. 

```{r include=FALSE}

# ols_step_backward_p(booking_lm2,
#                     prem = 0.05,
#                     progress = TRUE) -> booking_lm2_backward_p
# 
# # summary(booking_lm2_backward_p$model)
# 
# ols_step_backward_aic(booking_lm2,
#                       prem = 0.05,
#                       progress =  TRUE) -> booking_lm2_backward_AIC
 
#  summary(booking_lm2_backward_AIC$model)

#  the results are identical!

```


```{r include=FALSE}

# selected variables

booking_variables_selected <-
  booking_variables_selected[-which(booking_variables_selected %in% 
                                 c("reservation_status_date", 
                                   "arrival_date_week_number"))]
```

#### 2.2. Feature Transformation

Since we have continuous dependent variable, we will check the distribution of it. It is clearly right skewed as can seen from the left figure below. When we take logaritm of it, its shape is more close to normal. We will try to apply log transformation to see how models' accuracy change. 

```{r echo=FALSE, fig.width= 8}

# right-skewed distribution

adr1 <- ggplot(booking_train,
       aes(x = adr)) +
  geom_histogram(fill = "blue",
                 bins = 100) +
  theme_bw()


# more close to normal distribution

adr2 <- ggplot(booking_train,
       aes(x = log(adr + 1))) +
  geom_histogram(fill="darkgray",
                 bins = 100) +
  theme_bw()

grid.arrange(adr1, adr2, ncol=2)

```

Next step is constructing the model with log transformation for dependent variable (log(adr + 1)), and then all models constructed will be compared. The models were constructed with 5 folds cross validation. In below, all models is provided and results of accuracies will be given following steps. 

```{r echo=TRUE, warning=FALSE}

ctrl_cv5 <- trainControl(method = "cv",
                         number = 5)

# model with all variables
set.seed(987654321)

booking_lm0_all <- train(adr ~ .,
                         data = booking_train,
                         method  = "lm",
                         trControl = ctrl_cv5)

# model with selected variables
set.seed(987654321)
booking_lm0_selected <- train(adr ~ .,
                              data = booking_train %>%
                              dplyr::select(all_of(booking_variables_selected)),
                              method  = "lm",
                              trControl = ctrl_cv5)
                          

# model with all variables and log transformation in target variable adr
set.seed(987654321)
booking_lm1_all_log <- train(log(adr + 1) ~ .,
                             data = booking_train,
                             method  = "lm",
                             trControl = ctrl_cv5)

# model with selected variables and log transformation in target variable adr
set.seed(987654321)

booking_lm1_selected_log <- train(log(adr + 1) ~ .,
                                  data = booking_train %>%
                                  dplyr::select(all_of(booking_variables_selected)),
                                  method  = "lm",
                                  trControl = ctrl_cv5)

```

```{r echo=FALSE, warning=FALSE}

source("F_regression_metrics.R")

booking_models_list <- list(booking_lm0_all = booking_lm0_all,
                            booking_lm0_selected = booking_lm0_selected,
                            booking_lm1_all_log = booking_lm1_all_log,
                            booking_lm1_selected_log = booking_lm1_selected_log)

booking_models_list %>% 
  sapply(function(x) predict(x, newdata = booking_train)) %>% 
  data.frame() -> booking_fitted

# head(booking_fitted)

# converting log transformation to original 

booking_fitted$booking_lm1_all_log <- 
  exp(booking_fitted$booking_lm1_all_log) - 1

booking_fitted$booking_lm1_selected_log <-
  exp(booking_fitted$booking_lm1_selected_log) - 1

 #head(booking_fitted)


booking_models_list %>% 
  sapply(function(x) predict(x, newdata = booking_test)) %>% 
  data.frame() -> booking_forecast

# converting log transformation to original 

booking_forecast$booking_lm1_all_log <- 
  exp(booking_forecast$booking_lm1_all_log) - 1

booking_forecast$booking_lm1_selected_log <-
  exp(booking_forecast$booking_lm1_selected_log) - 1

# head(booking_forecasts)

r1 <- sapply(booking_fitted,
       function(x) regressionMetrics(
                                     booking_train$adr, x)) %>% 
  t()

r2 <- sapply(booking_forecast,
       function(x) regressionMetrics(
                                     booking_test$adr, x)) %>% 
  t()


```

```{r echo=FALSE, results= 'asis'}

kable(r1, caption = "Regression Metrics of Fitted Prediction on Train Data") %>%
  kable_styling(font_size = 10,  bootstrap_options = "bordered")


kable(r2, caption = "Regression Metrics of Forecasts on Test Data") %>%
  kable_styling(font_size = 10, bootstrap_options = "bordered")

```

First table above shows the fitted predictions on the train dataset. The elimination of some variables did not make a much difference in models since R2 of the both models (booking_lm0_all and booking_lm0_selected) are so close to each other. RMSE of these models are not too high and the difference in RMSE for both models is small (~0.023). There are NaNs in MSLE. It implies that there are some negative predicted variables and the formula cannot tkae the logarithm of them. 

When we take the logarithm of the response variable, R2 decreased a little. In the log transformed models (all variables vs selected variables), there is too little difference in R2s and taking logarithm caused a decrease in R2. 

Second table above shows the forecast values on the test dataset. The prediction errors on the test data is similar to prediciton in the train data. MSE increased a little for the prediction on the test data. 

<br>

After trying different linear models, now we will try to compare our models with other methods. The following section shows different machine learning methods for comparison with linear regression. 


#### 2.3. Model Comparison

In this section; models with KNN, SVM and Ridge - LASSO methods were constructed and they will be compared with accuracy of the linear regression. The model was selected as the reference model (booking_lm0_all) since it has the highest R2. 

###### 2.3.1. KNN

R codes of this method is provided in the RMarkdown file. However, this code takes too long time to compute the model. 
```{r}
## knn
# options(contrasts = c("contr.treatment",  # for non-ordinal factors
#                       "contr.treatment")) # for ordinal factors
# 
# sqrt(nrow(booking_train))
# 
# k_value <- data.frame(k = 287)
# 
# set.seed(987654321)
# 
# booking_lm_knn <-train(log(adr + 1) ~.,
#                         data = booking_train %>%
#                         dplyr::select(all_of(booking_variables_selected)),
#                         method  = "knn",
#                         trControl = ctrl_cv5) 
# 
# booking_lm_knn_fitted <- predict(booking_lm_knn,
#                                    booking_train)
# 
# booking_lm_knn_fitted <- exp(booking_lm_knn_fitted) -1
# 
# 
# booking_lm_knn_forecast <- predict(booking_lm_knn,
#                                  booking_test)
# 
# booking_lm_knn_forecast <- exp(booking_lm_knn_forecast) -1
# 
# 
# regressionMetrics(booking_train$adr, booking_lm_knn_fitted )
# regressionMetrics(booking_test$adr, booking_lm_knn_forecast )

```

###### 2.3.2. SVM

R codes of this method is provided in the RMarkdown file. However, this code takes too long time to compute the model. 

```{r}

# # linear
# 
# options(contrasts = c("contr.treatment",  # for non-ordinal factors
#                       "contr.treatment")) # for ordinal factors
# 
# # parametersC <- data.frame(C = c(0.001, 0.01, 0.02, 0.05, 
# #                                 0.1, 0.2, 0.5, 1, 2, 5))
# 
# set.seed(987654321)
# 
# booking.svm_Linear <- train(adr ~ ., 
#                             data = booking_train %>%
#                               dplyr::select(all_of(booking_variables_selected)), 
#                            method = "svmLinear",
#                            # tuneGrid = parametersC,
#                            trControl = ctrl_cv5)
# 
# booking.svm_Linear
# 
# ## poly
# 
# svm_parametersPoly <- expand.grid(C = c(0.001, 1),
#                                   degree = 2:5, 
#                                   scale = 1)
# 
# svm_parametersPoly
# 
# set.seed(987654321)
# 
# booking.svm_poly <- train(adr ~ ., 
#                         data = booking_train %>%
#                           dplyr::select(all_of(booking_variables_selected)), 
#                         method = "svmPoly",
#                         # tuneGrid = svm_parametersPoly,
#                         trControl = ctrl_cv5)
# 
# booking.svm_poly
# 
# # radial
# 
# parametersC_sigma <- 
#   expand.grid(C = c(0.01, 0.05, 0.1, 0.5, 1, 5),
#               sigma = c(0.05, 0.1, 0.2, 0.5, 1))
# 
# set.seed(987654321)
# 
# booking.svm_Radial <- train(adr ~ ., 
#                             data = booking_train %>%
#                               dplyr::select(all_of(booking_variables_selected)),  
#                            method = "svmRadial",
#                            tuneGrid = parametersC_sigma,
#                            trControl = ctrl_cv5)
# 
# plot(booking.svm_Radial$finalModel)
# 
# booking.svm_Radial_forecast <- predict(booking.svm_Radial, 
#                                        data2_test)
# 
# 
# regressionMetrics(booking_test$adr, booking.svm_Radial_forecast)
# 
# 
# 
# data2.svm_Radial1

```

###### 2.3.3. Ridge-LASSO

The model was constructed with mixed method that gives the optimal result between Ridge and LASSO methods.

```{r}



# mixed method

# parameters_elastic <- expand.grid(alpha = seq(0, 1, 0.2),
#                                  lambda = seq(10, 1e4, 10))
# set.seed(987654321)
# 
# booking_elastic <- train(adr ~ .,
#                        data = booking_train %>%
#                        dplyr::select(all_of(booking_variables_selected)),
#                        method = "glmnet",
#                        tuneGrid = parameters_elastic,
#                        trControl = ctrl_cv5)
# 
# head(booking_elastic, 10)
# 
# elastic_fitted <- predict(booking_elastic, booking_train)
# 
# elastic_forecast <- predict(booking_elastic, booking_test)
# 
# 
# 
# s1 <- sapply(elastic_fitted,
#        function(x) regressionMetrics(
#                                      booking_train$adr, x)) %>% 
#   t()
# 
# s2 <- sapply(elastic_forecast,
#        function(x) regressionMetrics(
#                                      booking_test$adr, x)) %>% 
#   t()
# 
# kable(s1, caption = "Regression Metrics of Fitted Prediction of Mixed Ridge-LASSO") %>%
#    kable_styling(font_size = 10, bootstrap_options = "bordered")
# 
# kable(s2, caption = "Regression Metrics of Forecasts on Mixed Ridge-LASSO") %>%
#    kable_styling(font_size = 10, bootstrap_options = "bordered")
# 

```

From the result table of mixed model of Ridge & LASSO methods, it can be said that Ridge method is better for this dataset. And optimal lambda value is estimated as 10. As lambda is increasing, RMSE is increasing as expected. 

The forecasts on the test data showed that there is an decrease in R2 for the mixed model. MSE, RMSE, MedAE and MSLE values increased a little. So, errors get high if we use this model and also the model accuracy get lower. 

```{r echo=FALSE}

 # plot(booking_elastic)

```

In the plot, the model accuracies was tested with diffrent alpha. Alpha = 0 implies Ridge model while alpha = 1 implies LASSO model. From the plot blue line gives the Ridge model's parameters and as can seen it is better in all alpha values. 


### 2. SUMMARY AND CONCLUSION

In this project, hotel booking demand dataset was used for linear regression. Initial step was preparation of the dataset for the analysis. First, variables were converted to the true types (integer to factor). After that, dataset divided into train and test sample. Then, correlations for numerical variables, ANOVA tests for categorical variables and possible linear combinations of variables were checked to see the possible uncessary variables to eliminate. After that, variables having zero variances was checked. As a result of these test, 5 variables were eliminated from the model.  A reference linear regression model was constructed to compare with different models. Then, backward elimination was applied on the train data. 2 features including reservation_status and reservation_status_date were not included in the linear regression as a result of the backward elimination. The next step was log transformation of target variable. After transformation, the accuracy measures of the models decreased a little. Last step was comparing the prediction accuracy on the test data. According to the results, the reference model gave better results among all models. 

*** 



